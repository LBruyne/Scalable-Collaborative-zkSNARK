use std::{collections::HashMap, hint::black_box};

use ark_ec::pairing::Pairing;
use ark_ff::FftField;
use ark_std::UniformRand;
use ark_std::One;

use ark_serialize::Compress;
use dist_primitive::{
    degree_reduce::degree_reduce_many,
    dpoly_comm::{PolynomialCommitment, PolynomialCommitmentCub},
    dsumcheck::d_sumcheck_product,
    mle::PackedDenseMultilinearExtension,
    utils::serializing_net::MPCSerializeNet,
};
use mpc_net::{MPCNetError, MultiplexedStreamID};
use mpc_net::{end_timer, start_timer};
use secret_sharing::pss::PackedSharingParams;

use crate::gkr::SparseMultilinearExtension;


#[derive(Clone, Debug)]
pub struct PackedProvingParameters<E: Pairing> {
    // Packed shares of f1 and V
    pub f1s: Vec<SparseMultilinearExtension<E::ScalarField>>,
    pub poly_vs: Vec<PackedDenseMultilinearExtension<E::ScalarField>>,
    // Challenges
    pub challenge_g: Vec<E::ScalarField>,
    pub challenge_u: Vec<E::ScalarField>,
    pub challenge_v: Vec<E::ScalarField>,
    pub challenge_r: Vec<E::ScalarField>,
    pub commitment: PolynomialCommitment<E>
}

impl<E: Pairing> PackedProvingParameters<E> {
    pub fn new(depth: usize, width: usize, l: usize, pp: &PackedSharingParams<E::ScalarField>) -> Self {
        use rand::{rngs::StdRng, SeedableRng};

        let rng = &mut StdRng::from_entropy();
        // Shares of a polynomial representing mult and add.
        let mut f1 = SparseMultilinearExtension::<<E as Pairing>::ScalarField>(HashMap::new());
        for _ in 0..((1 << width) / l) {
            f1.0.insert(
                (
                    <E as Pairing>::ScalarField::rand(rng),
                    <E as Pairing>::ScalarField::rand(rng),
                    <E as Pairing>::ScalarField::rand(rng),
                ),
                <E as Pairing>::ScalarField::one(),
            );
        }
        let f1s = vec![f1; depth];
        // Shares of a polynomial representing V.
        let poly_v =
            PackedDenseMultilinearExtension::<<E as Pairing>::ScalarField>::from_evaluations_slice(
                0,
                &(0..(1 << (width - pp.l.trailing_zeros() as usize)))
                    .map(|_| <E as Pairing>::ScalarField::rand(rng))
                    .collect::<Vec<_>>(),
            );
        let poly_vs = vec![poly_v; depth];
        // Shares of challenge g, u, v, r. For benchmarking purposes, we generate them in advance and use them repeatedly in the protocol.
        // In the real protocol, g's shares should be generated by a f_rand protocol.
        let challenge_g: Vec<<E as Pairing>::ScalarField> = (0..width)
            .map(|_| <E as Pairing>::ScalarField::rand(rng))
            .collect::<Vec<_>>();
        let challenge_u: Vec<<E as Pairing>::ScalarField> = (0..width)
            .map(|_| <E as Pairing>::ScalarField::rand(rng))
            .collect::<Vec<_>>();
        let challenge_v: Vec<<E as Pairing>::ScalarField> = (0..width)
            .map(|_| <E as Pairing>::ScalarField::rand(rng))
            .collect::<Vec<_>>();
        let challenge_r: Vec<<E as Pairing>::ScalarField> = (0..width)
            .map(|_| <E as Pairing>::ScalarField::rand(rng))
            .collect::<Vec<_>>();
        // Polynomial commitment.
        let commitment = PolynomialCommitmentCub::<E>::new_single(width, &pp);
    
        PackedProvingParameters {
            f1s,
            poly_vs,
            challenge_g,
            challenge_u,
            challenge_v,
            challenge_r,
            commitment
        }
    }
}

/// This is a proof-of-concept implementation of the distributed GKR function.
/// The following implementation is valid only for data-parallel circuits.
pub async fn d_gkr_function<F: FftField, Net: MPCSerializeNet>(
    shares_f1: &SparseMultilinearExtension<F>,
    shares_f2: &PackedDenseMultilinearExtension<F>,
    shares_f3: &PackedDenseMultilinearExtension<F>,
    challenge_g: &Vec<F>,
    challenge_u: &Vec<F>,
    challenge_v: &Vec<F>,
    pp: &PackedSharingParams<F>,
    net: &Net,
    sid: MultiplexedStreamID,
) -> Result<Vec<(F, F, F)>, MPCNetError> {
    // Init Phase 1
    let hg = d_initialize_phase_one(shares_f1, shares_f3, challenge_g, pp, net, sid).await?;
    // Sumcheck product 1
    let mut proof1 =
        d_sumcheck_product(&hg.shares, &shares_f2.shares, challenge_u, pp, net, sid).await?;
    // Init Phase 2
    let f1 = d_initialize_phase_two(shares_f1, challenge_g, challenge_v, pp, net, sid).await?;
    // Calculate f3*f2(u). Omitted for simplicity.
    // let f2_u = d_fix_variable(&shares_f2.shares, challenge_u, pp, net, sid).await?[0];
    // let f2_u = d_unpack_0(f2_u, pp, net, sid).await?;
    let f2_u = F::one();
    let shares_f3_f2u = shares_f3.mul(&f2_u);
    // Sumcheck product 2
    let proof2 =
        d_sumcheck_product(&f1.shares, &shares_f3_f2u.shares, challenge_v, pp, net, sid).await?;
    proof1.extend(proof2);
    Ok(proof1)
}

pub async fn d_initialize_phase_one<F: FftField, Net: MPCSerializeNet>(
    shares_f1: &SparseMultilinearExtension<F>,
    shares_f3: &PackedDenseMultilinearExtension<F>,
    challenge_g: &Vec<F>,
    pp: &PackedSharingParams<F>,
    net: &Net,
    sid: MultiplexedStreamID,
) -> Result<PackedDenseMultilinearExtension<F>, MPCNetError> {
    black_box(shares_f1);
    black_box(shares_f3);
    black_box(challenge_g);
    Ok(PackedDenseMultilinearExtension::from_evaluations_slice(
        challenge_g.len(),
        &d_phase_initilization(shares_f1, pp, net, sid).await?,
    ))
}

pub async fn d_initialize_phase_two<F: FftField, Net: MPCSerializeNet>(
    shares_f1: &SparseMultilinearExtension<F>,
    challenge_g: &Vec<F>,
    challenge_v: &Vec<F>,
    pp: &PackedSharingParams<F>,
    net: &Net,
    sid: MultiplexedStreamID,
) -> Result<PackedDenseMultilinearExtension<F>, MPCNetError> {
    // Now this comes from Father Christmas
    black_box(shares_f1);
    black_box(challenge_g);
    black_box(challenge_v);
    Ok(PackedDenseMultilinearExtension::from_evaluations_slice(
        challenge_g.len(),
        &d_phase_initilization(shares_f1, pp, net, sid).await?,
    ))
}

/// This is a simplified version to mimic the complexity.
pub async fn d_phase_initilization<F: FftField, Net: MPCSerializeNet>(
    shares_f1: &SparseMultilinearExtension<F>,
    pp: &PackedSharingParams<F>,
    net: &Net,
    sid: MultiplexedStreamID,
) -> Result<Vec<F>, MPCNetError> {
    let all_timer = start_timer!("Phase Initialization", net.is_leader());
    let timer = start_timer!("Local: Something", net.is_leader());
    let mut evaluations = vec![F::zero(); shares_f1.0.len()];
    shares_f1.0.iter().enumerate().for_each(|(id, (_, v))| {
        evaluations[id] += *v * *v;
    });
    // Act a degree reduction.
    // Note that each party only suffers from 1/N cost.
    let shares = evaluations[..shares_f1.0.len() / net.n_parties()].to_vec();
    end_timer!(timer);
    let shares = degree_reduce_many(&shares, pp, net, sid)
        .await?
        .iter()
        .cycle()
        .take(shares_f1.0.len())
        .cloned()
        .collect::<Vec<_>>();
    // Add the communication it should have.
    // Is this correct?
    net.add_comm(
        F::zero().serialized_size(Compress::No) * (net.n_parties() - 1) * net.n_parties(),
        F::zero().serialized_size(Compress::No) * (net.n_parties() - 1) * net.n_parties(),
    );
    end_timer!(all_timer);
    Ok(shares)
}

/// A proof-of-concept implementation of distributed GKR proof.
/// Assume the party has required pre-processings.
pub async fn d_gkr<E: Pairing, Net: MPCSerializeNet>(
    depth: usize,
    width: usize,
    pk: &PackedProvingParameters<E>,
    pp: &PackedSharingParams<E::ScalarField>,
    net: &Net,
    sid: MultiplexedStreamID,
) -> Result<
    (
        Vec<Vec<Vec<(E::ScalarField, E::ScalarField, E::ScalarField)>>>,
        E::G1,
        (E::ScalarField, Vec<E::G1>),
    ),
    MPCNetError,
> {
    let _ = width;
    let mut proof = Vec::new();

    let timer_all =
        start_timer!("Distributed GKR", net.is_leader());

    // Commit
    let commit_timer = start_timer!("Commit", net.is_leader());
    let commit = pk.commitment
        .d_commit(&vec![pk.poly_vs[0].shares.clone()], pp, net, sid)
        .await?;
    end_timer!(commit_timer);

    let prover_timer = start_timer!("Distributed GKR Prover", net.is_leader());

    let timer_gkr_rounds = start_timer!("GKR rounds", net.is_leader());
    for _ in 0..depth {
        let mut layer_proof = Vec::new();
        // For GKR relation,
        // in each round we actually need to run 3 GKR functions.
        // 1 with the form mult(g,x,y)V(x)V(y)
        // 2 with the form add(g,x,y)V(x) and add(g,x,y)V(y)
        // To mimic, at last we run 3 GKR functions in each layer.
        for _ in 0..3 {
            layer_proof.push(
                d_gkr_function(
                    black_box(&pk.f1s[0]),
                    black_box(&pk.poly_vs[0]),
                    black_box(&pk.poly_vs.clone()[0]),
                    black_box(&pk.challenge_g.clone()),
                    black_box(&pk.challenge_u.clone()),
                    black_box(&pk.challenge_v.clone()),
                    pp,
                    net,
                    sid,
                )
                .await?,
            );
        }
        proof.push(layer_proof);
    }
    end_timer!(timer_gkr_rounds);

    // Open
    let open_timer = start_timer!("Open", net.is_leader());
    let open = pk.commitment
        .d_open(&pk.poly_vs[depth-1].shares, &pk.challenge_r, pp, net, sid)
        .await?;
    end_timer!(open_timer);

    end_timer!(prover_timer);

    end_timer!(timer_all);

    if net.is_leader() {
        println!("Comm: {:?}", net.get_comm());
    }

    Ok((proof, commit[0], open))
}
